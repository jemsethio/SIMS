{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRMM PNG monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xray\n",
    "from netCDF4 import MFDataset\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "import palettable\n",
    "import folium\n",
    "from folium.map import FeatureGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain = {'latmin':-13, 'lonmin':155., 'latmax':-5, 'lonmax':168.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_netcdfs(files, dim, transform_func=None):\n",
    "    def process_one_path(path):\n",
    "        # use a context manager, to ensure the file gets closed after use\n",
    "        with xray.open_dataset(path) as ds:\n",
    "            # transform_func shdset_clim = dset_clim.sel(lat=slice(domain['latmin'], domain['latmax']), could do some sort of selection or\n",
    "            # aggregation\n",
    "            if transform_func is not None:\n",
    "                ds = transform_func(ds)\n",
    "            # load all data from the transformed dataset, to ensure we can\n",
    "            # use it after closing each original file\n",
    "            ds.load()\n",
    "            return ds\n",
    "\n",
    "    #paths = sorted(glob(files))\n",
    "    datasets = [process_one_path(p) for p in files]\n",
    "    combined = xray.concat(datasets, dim)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpath = '/Users/nicolasf/data/TRMM/daily/'\n",
    "climpath = '/Users/nicolasf/data/TRMM/climatology/daily/2001_2015/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today = datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trmm_date = today - timedelta(days=lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-30 02:59:24.014464\n"
     ]
    }
   ],
   "source": [
    "print(trmm_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndays = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realtime = pd.date_range(start=trmm_date - timedelta(days=ndays-1), end=trmm_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lfiles = []\n",
    "for d in realtime: \n",
    "    fname  = dpath + \"3B42RT_daily.{}.nc\".format(d.strftime(\"%Y.%m.%d\"))\n",
    "    lfiles.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-554236db3ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdset_realtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_netcdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-2bfa52904976>\u001b[0m in \u001b[0;36mread_netcdfs\u001b[0;34m(files, dim, transform_func)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#paths = sorted(glob(files))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess_one_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2bfa52904976>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#paths = sorted(glob(files))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess_one_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2bfa52904976>\u001b[0m in \u001b[0;36mprocess_one_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_one_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# use a context manager, to ensure the file gets closed after use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mxray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;31m# transform_func shdset_clim = dset_clim.sel(lat=slice(domain['latmin'], domain['latmax']), could do some sort of selection or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m# aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicolasf/anaconda/envs/Root/lib/python3.5/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, engine, chunks, lock, drop_variables)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                              allow_remote=True)\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'netcdf4'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetCDF4DataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScipyDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicolasf/anaconda/envs/Root/lib/python3.5/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, format, group, writer, clobber, diskless, persist)\u001b[0m\n\u001b[1;32m    186\u001b[0m         ds = nc4.Dataset(filename, mode=mode, clobber=clobber,\n\u001b[1;32m    187\u001b[0m                          \u001b[0mdiskless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiskless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                          format=format)\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__ (netCDF4/_netCDF4.c:12617)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: No such file or directory"
     ]
    }
   ],
   "source": [
    "dset_realtime = read_netcdfs(lfiles, 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset_realtime = dset_realtime.sel(lat=slice(domain['latmin'], domain['latmax']), \\\n",
    "                                  lon=slice(domain['lonmin'], domain['lonmax']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clim_files = []\n",
    "for d in realtime: \n",
    "    fname  = climpath + \"3B42_daily.{}.nc\".format(d.strftime(\"%m.%d\"))\n",
    "    clim_files.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset_clim = read_netcdfs(clim_files, 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset_clim = dset_clim.sel(lat=slice(domain['latmin'], domain['latmax']), \\\n",
    "                          lon=slice(domain['lonmin'], domain['lonmax']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dset_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reads in the location for the virtual stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Virtual_Stations = pd.read_csv('../data/station_list_Solomon_lat_lon.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Virtual_Stations.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsums = {}\n",
    "\n",
    "for i, row in Virtual_Stations.iterrows(): \n",
    "    stn_name = row['name_primary']\n",
    "    lat_V = row['latitude']\n",
    "    lon_V = row['longitude']\n",
    "\n",
    "    \n",
    "    clim_ts = dset_clim.sel(lat=lat_V, lon=lon_V, method='nearest')['trmm']\n",
    "    realtime_ts = dset_realtime.sel(lat=lat_V, lon=lon_V, method='nearest')['trmm']\n",
    "    df_ts = realtime_ts.to_dataframe()[['trmm']]\n",
    "    df_ts.loc[:,'clim'] = clim_ts.data\n",
    "    df_ts.columns = ['observed','climatology']\n",
    "    sums = df_ts.sum()\n",
    "    dsums[stn_name] = sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dsums = pd.DataFrame(dsums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dsums = df_dsums.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dsums = df_dsums.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dsums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = {}\n",
    "for i, row in Virtual_Stations.iterrows():         \n",
    "    stn_name = row['name_primary']\n",
    "    lat_V = row['latitude']\n",
    "    lon_V = row['longitude']\n",
    "    cities[stn_name] = (lat_V, lon_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Virtual_Stations.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fmap = folium.Map(location=[-9, 163], zoom_start=6, min_lon = 0., max_lon = 360., detect_retina=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the background layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add = '/tile/{z}/{y}/{x}'\n",
    "\n",
    "ESRI = {}\n",
    "ESRI['World Imagery'] = 'http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer'\n",
    "ESRI['World Topography'] = 'http://services.arcgisonline.com/arcgis/rest/services/World_Topo_Map/MapServer'\n",
    "ESRI['Street Map'] = 'http://services.arcgisonline.com/arcgis/rest/services/World_Street_Map/MapServer'\n",
    "\n",
    "for tile_name in ['World Imagery','World Topography','Street Map']:\n",
    "    tile_url = ESRI[tile_name]\n",
    "    tile_url += add\n",
    "    fmap.add_tile_layer(name=tile_name,\n",
    "                     tiles=tile_url, attr='ESRI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a feature group which will include the stations markers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Solomon_stations = FeatureGroup(name='Show Solomon Islands Stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_icon = (188, 325)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loops over the stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in Virtual_Stations.index:\n",
    "    \n",
    "    data = Virtual_Stations.ix[i]\n",
    "    \n",
    "    name_primary = data.name_primary\n",
    "    \n",
    "    obs = df_dsums.ix[name_primary].values[0]\n",
    "    clim = df_dsums.ix[name_primary].values[1]\n",
    "    \n",
    "    anom = (obs / clim) * 100\n",
    "    \n",
    "    html = \"\"\"\n",
    "    <font face=\"verdana\">\n",
    "    <div align='center'><h4>\n",
    "    Last 90 days (to the {:%Y-%m-%d UTC}) estimates [TRMM/TMPA] for {}</h4>\n",
    "    observed = <b>{}</b> mm <br>\n",
    "    climatology = <b>{}</b> mm <br>\n",
    "    percent. of normal = <b>{:4.2f}<b> %\n",
    "    <br><br>\n",
    "    <a href=\"https://cdn.rawgit.com/nicolasfauchereau/SIMS/master/TRMM/www/Virtual_Station_{}_90ndays.html\" target=\"_blank\">click here for the time-series</a>\n",
    "    </font>\n",
    "    \"\"\".format(trmm_date, name_primary, obs, clim, anom, name_primary)\n",
    "        \n",
    "    iframe = folium.element.IFrame(html=html, width=300, height=200)\n",
    "    \n",
    "    popup = folium.Popup(iframe, max_width=600)\n",
    "    \n",
    "    if anom <= 40: \n",
    "        icon = folium.features.CustomIcon('https://raw.githubusercontent.com/nicolasfauchereau/SIMS/master/TRMM/images/icons/orange.png',\\\n",
    "                                         icon_size=(size_icon[0]*0.05, size_icon[1]*0.05))\n",
    "        marker = folium.map.Marker([data.latitude, data.longitude], icon=icon, popup=popup)   \n",
    "    elif (anom > 40) & (anom <= 80):\n",
    "        icon = folium.features.CustomIcon('https://raw.githubusercontent.com/nicolasfauchereau/SIMS/master/TRMM/images/icons/yellow.png',\\\n",
    "                                         icon_size=(size_icon[0]*0.1, size_icon[1]*0.1))\n",
    "        marker = folium.map.Marker([data.latitude, data.longitude], icon=icon, popup=popup)   \n",
    "    elif (anom > 80) & (anom < 120):\n",
    "        icon = folium.features.CustomIcon('https://raw.githubusercontent.com/nicolasfauchereau/SIMS/master/TRMM/images/icons/green.png',\\\n",
    "                                         icon_size=(size_icon[0]*0.15, size_icon[1]*0.15))\n",
    "        marker = folium.map.Marker([data.latitude, data.longitude], icon=icon, popup=popup)  \n",
    "    elif (anom >= 120) & (anom < 160):\n",
    "        icon = folium.features.CustomIcon('https://raw.githubusercontent.com/nicolasfauchereau/SIMS/master/TRMM/images/icons/blue.png',\\\n",
    "                                         icon_size=(size_icon[0]*0.2, size_icon[1]*0.2))\n",
    "        marker = folium.map.Marker([data.latitude, data.longitude], icon=icon, popup=popup)  \n",
    "    elif anom > 160:\n",
    "        icon = folium.features.CustomIcon('https://raw.githubusercontent.com/nicolasfauchereau/SIMS/master/TRMM/images/icons/deepblue.png',\\\n",
    "                                         icon_size=(size_icon[0]*0.25, size_icon[1]*0.25))\n",
    "        marker = folium.map.Marker([data.latitude, data.longitude], icon=icon, popup=popup)  \n",
    "    \n",
    "#     c = folium.CircleMarker(location=[data.latitude, data.longitude], popup=popup, color='red', fill_color='red', \\\n",
    "#                         fill_opacity=0.4, radius=5000)\n",
    "    \n",
    "#     c  = folium.Marker(location=[data.latitude, data.longitude], popup=popup)\n",
    "    \n",
    "    # add to fature group\n",
    "    Solomon_stations.add_children(marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fmap.add_children(Solomon_stations)\n",
    "fmap.add_children(folium.map.LayerControl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fmap.save('./interactive_map_Solomon.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
